{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import model\n",
    "import data_loader\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_softmax(input_tensor, temperature=1.0):\n",
    "    return torch.softmax(input_tensor / temperature, dim=1)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "batch_size = 256\n",
    "train_iter, test_iter = data_loader.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=784, out_features=1000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear2): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define teacher & stduent model, Move models and data to GPU, Initialize weights\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher = model.TeacherModel().to(device)\n",
    "student = model.Student().to(device)\n",
    "student_distill = model.Student().to(device)\n",
    "student.apply(weights_init)\n",
    "student_distill.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "criterion_student = nn.CrossEntropyLoss()\n",
    "criterion_student_distill = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.RMSprop(teacher.parameters(), lr=1e-4)\n",
    "optimizer_student = optim.SGD(student.parameters(), lr=0.01)\n",
    "optimizer_student_distill = optim.SGD(student_distill.parameters(), lr=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 1.8642696715415792, test_loss = 1.7459946632385255, accuracy = 0.7363\n",
      "Epoch 2, loss = 1.7335356159413116, test_loss = 1.7093547224998473, accuracy = 0.762\n",
      "Epoch 3, loss = 1.7068078888223526, test_loss = 1.6949671268463136, accuracy = 0.7694\n",
      "Epoch 4, loss = 1.6921150567683767, test_loss = 1.677220532298088, accuracy = 0.7856\n",
      "Epoch 5, loss = 1.6802283165302683, test_loss = 1.6674225866794585, accuracy = 0.7975\n",
      "Epoch 6, loss = 1.6693116629377325, test_loss = 1.6567104518413545, accuracy = 0.8062\n",
      "Epoch 7, loss = 1.661570366900018, test_loss = 1.648829346895218, accuracy = 0.8142\n",
      "Epoch 8, loss = 1.6550766062229239, test_loss = 1.64264377951622, accuracy = 0.8205\n",
      "Epoch 9, loss = 1.6506536204764184, test_loss = 1.6369083285331727, accuracy = 0.8271\n",
      "Epoch 10, loss = 1.6453787382612837, test_loss = 1.633430165052414, accuracy = 0.8296\n",
      "Epoch 11, loss = 1.6403011347385164, test_loss = 1.6241026699543, accuracy = 0.839\n",
      "Epoch 12, loss = 1.6378359332997747, test_loss = 1.6258205235004426, accuracy = 0.8379\n",
      "Epoch 13, loss = 1.6350263499199076, test_loss = 1.6186931371688842, accuracy = 0.8462\n",
      "Epoch 14, loss = 1.6312563373687419, test_loss = 1.6169560641050338, accuracy = 0.8482\n",
      "Epoch 15, loss = 1.6295964530173768, test_loss = 1.6142057538032533, accuracy = 0.85\n",
      "Epoch 16, loss = 1.6278603822626967, test_loss = 1.6141117066144943, accuracy = 0.8494\n",
      "Epoch 17, loss = 1.6258217334747314, test_loss = 1.611589503288269, accuracy = 0.853\n",
      "Epoch 18, loss = 1.6239048749842542, test_loss = 1.6080346286296845, accuracy = 0.8554\n",
      "Epoch 19, loss = 1.621665470143582, test_loss = 1.606797680258751, accuracy = 0.8564\n",
      "Epoch 20, loss = 1.619358627339627, test_loss = 1.6049799025058746, accuracy = 0.8595\n",
      "Epoch 21, loss = 1.6177753164413127, test_loss = 1.6010534465312958, accuracy = 0.8615\n",
      "Epoch 22, loss = 1.6160586210007364, test_loss = 1.6036348730325698, accuracy = 0.8603\n",
      "Epoch 23, loss = 1.6144343036286375, test_loss = 1.6003560364246368, accuracy = 0.8622\n",
      "Epoch 24, loss = 1.6125785056580888, test_loss = 1.5992356717586518, accuracy = 0.8637\n",
      "Epoch 25, loss = 1.612700301535586, test_loss = 1.5982196748256683, accuracy = 0.8646\n",
      "Epoch 26, loss = 1.6110898651975267, test_loss = 1.5947055041790008, accuracy = 0.867\n",
      "Epoch 27, loss = 1.609729370665043, test_loss = 1.5961659371852874, accuracy = 0.8662\n",
      "Epoch 28, loss = 1.6088276579024945, test_loss = 1.598968955874443, accuracy = 0.8635\n",
      "Epoch 29, loss = 1.6087561211687453, test_loss = 1.5978057473897933, accuracy = 0.8648\n",
      "Epoch 30, loss = 1.6069834364221451, test_loss = 1.5935530334711074, accuracy = 0.8681\n",
      "Epoch 31, loss = 1.6055286823435033, test_loss = 1.5967146545648574, accuracy = 0.8649\n",
      "Epoch 32, loss = 1.6049773789466695, test_loss = 1.5952455788850783, accuracy = 0.8658\n",
      "Epoch 33, loss = 1.6041833573199333, test_loss = 1.592576077580452, accuracy = 0.8686\n",
      "Epoch 34, loss = 1.602930093318858, test_loss = 1.5934832334518432, accuracy = 0.8685\n",
      "Epoch 35, loss = 1.6023141642834278, test_loss = 1.590298056602478, accuracy = 0.8707\n",
      "Epoch 36, loss = 1.601855199387733, test_loss = 1.5908432126045227, accuracy = 0.8698\n",
      "Epoch 37, loss = 1.6017149179539782, test_loss = 1.587690457701683, accuracy = 0.8731\n",
      "Epoch 38, loss = 1.6001423206735164, test_loss = 1.5912786632776261, accuracy = 0.87\n",
      "Epoch 39, loss = 1.601093696026092, test_loss = 1.5901711374521255, accuracy = 0.8699\n",
      "Epoch 40, loss = 1.5977445764744536, test_loss = 1.5884835600852967, accuracy = 0.8735\n",
      "Epoch 41, loss = 1.5985213741343072, test_loss = 1.5884656995534896, accuracy = 0.8726\n",
      "Epoch 42, loss = 1.598201906427424, test_loss = 1.5903189301490783, accuracy = 0.8721\n",
      "Epoch 43, loss = 1.5963824982338763, test_loss = 1.5873826175928116, accuracy = 0.8748\n",
      "Epoch 44, loss = 1.595581778566888, test_loss = 1.5899720430374145, accuracy = 0.871\n",
      "Epoch 45, loss = 1.5950981444500862, test_loss = 1.5848024785518646, accuracy = 0.8757\n",
      "Epoch 46, loss = 1.5966564645158483, test_loss = 1.5879285901784896, accuracy = 0.8729\n",
      "Epoch 47, loss = 1.5943955624357182, test_loss = 1.5821673423051834, accuracy = 0.8789\n",
      "Epoch 48, loss = 1.5943584756648286, test_loss = 1.5835624426603316, accuracy = 0.8771\n",
      "Epoch 49, loss = 1.593713368253505, test_loss = 1.5834159582853318, accuracy = 0.8773\n",
      "Epoch 50, loss = 1.5916863811776993, test_loss = 1.5834798693656922, accuracy = 0.8767\n",
      "Epoch 51, loss = 1.5921957386300918, test_loss = 1.5821857064962388, accuracy = 0.8794\n",
      "Epoch 52, loss = 1.5910357769499435, test_loss = 1.5819538056850433, accuracy = 0.8785\n",
      "Epoch 53, loss = 1.5908816510058463, test_loss = 1.5824888944625854, accuracy = 0.8778\n",
      "Epoch 54, loss = 1.5897355703597373, test_loss = 1.5813365042209626, accuracy = 0.8801\n",
      "Epoch 55, loss = 1.590972539719115, test_loss = 1.5797535121440887, accuracy = 0.8794\n",
      "Epoch 56, loss = 1.5906492187621746, test_loss = 1.5815302848815918, accuracy = 0.8786\n",
      "Epoch 57, loss = 1.589126232837109, test_loss = 1.5791181087493897, accuracy = 0.8813\n",
      "Epoch 58, loss = 1.5894023651772358, test_loss = 1.5793367177248, accuracy = 0.8814\n",
      "Epoch 59, loss = 1.589144569254936, test_loss = 1.5782603412866592, accuracy = 0.8828\n",
      "Epoch 60, loss = 1.5878076791763305, test_loss = 1.5782126665115357, accuracy = 0.8826\n"
     ]
    }
   ],
   "source": [
    "train.train_teacher(teacher, optimizer_teacher, criterion_teacher, train_iter, test_iter, device,num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 1.657535027950368, test_loss = 1.6618335247039795, accuracy = 0.8077\n",
      "Epoch 2, loss = 1.6573216123783843, test_loss = 1.6618191599845886, accuracy = 0.8076\n",
      "Epoch 3, loss = 1.6570985154902682, test_loss = 1.6617167830467223, accuracy = 0.8075\n",
      "Epoch 4, loss = 1.6568438382858925, test_loss = 1.661665540933609, accuracy = 0.8073\n",
      "Epoch 5, loss = 1.6569274395070177, test_loss = 1.6613876849412919, accuracy = 0.8074\n",
      "Epoch 6, loss = 1.6567570427630811, test_loss = 1.661282330751419, accuracy = 0.808\n",
      "Epoch 7, loss = 1.6567995771448663, test_loss = 1.6611857563257217, accuracy = 0.8077\n",
      "Epoch 8, loss = 1.656761709172675, test_loss = 1.6610952943563462, accuracy = 0.8076\n",
      "Epoch 9, loss = 1.6562935088543183, test_loss = 1.6609951615333558, accuracy = 0.8081\n",
      "Epoch 10, loss = 1.6563612628490367, test_loss = 1.6608612060546875, accuracy = 0.8076\n",
      "Epoch 11, loss = 1.6562673259288707, test_loss = 1.6607503592967987, accuracy = 0.808\n",
      "Epoch 12, loss = 1.656211584679624, test_loss = 1.660696616768837, accuracy = 0.809\n",
      "Epoch 13, loss = 1.6559892948637618, test_loss = 1.6606335490942001, accuracy = 0.808\n",
      "Epoch 14, loss = 1.655710799643334, test_loss = 1.6605572670698165, accuracy = 0.8081\n",
      "Epoch 15, loss = 1.6551971207273768, test_loss = 1.6604179978370666, accuracy = 0.8081\n",
      "Epoch 16, loss = 1.6550545778680354, test_loss = 1.6602910488843918, accuracy = 0.8083\n",
      "Epoch 17, loss = 1.6556845456995863, test_loss = 1.6602512747049332, accuracy = 0.8082\n",
      "Epoch 18, loss = 1.6551272113272484, test_loss = 1.660153976082802, accuracy = 0.8081\n",
      "Epoch 19, loss = 1.65529309485821, test_loss = 1.6599418580532075, accuracy = 0.8086\n",
      "Epoch 20, loss = 1.6552970013719923, test_loss = 1.659903633594513, accuracy = 0.8085\n",
      "Epoch 21, loss = 1.6545518504812362, test_loss = 1.6598276942968369, accuracy = 0.8081\n",
      "Epoch 22, loss = 1.6550276274376727, test_loss = 1.659746527671814, accuracy = 0.8086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train\u001b[39m.\u001b[39;49mtrain_student(student, optimizer_student, criterion_student, train_iter, test_iter, device,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m)\n",
      "File \u001b[0;32m~/Knowledge-Distillation/1.Distilling-the-Knowledge-in-a-Neural-Network/train.py:47\u001b[0m, in \u001b[0;36mtrain_student\u001b[0;34m(net, optimizer, criterion, trainloader, testloader, device, num_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     46\u001b[0m \u001b[39m# if epoch % 5 == 5 - 1:\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m test_loss, accuracy \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39;49mevaluate_student(net, criterion, testloader, device)\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, loss = \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(trainloader)\u001b[39m}\u001b[39;00m\u001b[39m, test_loss = \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m}\u001b[39;00m\u001b[39m, accuracy = \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Knowledge-Distillation/1.Distilling-the-Knowledge-in-a-Neural-Network/evaluate.py:36\u001b[0m, in \u001b[0;36mevaluate_student\u001b[0;34m(net, criterion, testloader, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m testloader:\n\u001b[1;32m     37\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.conda/envs/corner/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.train_student(student, optimizer_student, criterion_student, train_iter, test_iter, device,num_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 2.0600950033106704, test_loss = 1.6672202110290528, accuracy = 0.7899\n",
      "Epoch 2, loss = 2.0494372281622377, test_loss = 1.6280801445245743, accuracy = 0.8321\n",
      "Epoch 3, loss = 2.0101762583915224, test_loss = 1.62460158765316, accuracy = 0.8346\n",
      "Epoch 4, loss = 2.004246626508997, test_loss = 1.6216260880231856, accuracy = 0.8384\n",
      "Epoch 5, loss = 2.0022594822214006, test_loss = 1.6220321565866471, accuracy = 0.8382\n",
      "Epoch 6, loss = 2.0001206986447597, test_loss = 1.6208615452051163, accuracy = 0.8393\n",
      "Epoch 7, loss = 1.998136794820745, test_loss = 1.6195638865232467, accuracy = 0.8391\n",
      "Epoch 8, loss = 1.9966309283642059, test_loss = 1.6192172318696976, accuracy = 0.8412\n",
      "Epoch 9, loss = 1.9952711120564888, test_loss = 1.6177712678909302, accuracy = 0.8432\n",
      "Epoch 10, loss = 1.994749869184291, test_loss = 1.6176768869161606, accuracy = 0.8424\n",
      "Epoch 11, loss = 1.992976856738963, test_loss = 1.6170044481754302, accuracy = 0.8429\n",
      "Epoch 12, loss = 1.9924973569017776, test_loss = 1.6163988679647445, accuracy = 0.8438\n",
      "Epoch 13, loss = 1.9916896348303936, test_loss = 1.6162153422832488, accuracy = 0.8439\n",
      "Epoch 14, loss = 1.9908985853195191, test_loss = 1.6154701441526413, accuracy = 0.845\n",
      "Epoch 15, loss = 1.989750291438813, test_loss = 1.6153894305229186, accuracy = 0.8453\n",
      "Epoch 16, loss = 1.9893373215452153, test_loss = 1.6151743471622466, accuracy = 0.8469\n",
      "Epoch 17, loss = 1.9883087675622169, test_loss = 1.6161721140146255, accuracy = 0.8441\n",
      "Epoch 18, loss = 1.9882796617264444, test_loss = 1.6143642008304595, accuracy = 0.8472\n",
      "Epoch 19, loss = 1.987416245582256, test_loss = 1.6145988821983337, accuracy = 0.8451\n",
      "Epoch 20, loss = 1.9864806109286368, test_loss = 1.6134308516979217, accuracy = 0.8478\n",
      "Epoch 21, loss = 1.9859759655404599, test_loss = 1.6144018828868867, accuracy = 0.8481\n",
      "Epoch 22, loss = 1.9851407583723677, test_loss = 1.6135469913482665, accuracy = 0.8471\n",
      "Epoch 23, loss = 1.9854604543523586, test_loss = 1.613724797964096, accuracy = 0.8476\n",
      "Epoch 24, loss = 1.9845068378651396, test_loss = 1.6136634081602097, accuracy = 0.8483\n",
      "Epoch 25, loss = 1.983842712260307, test_loss = 1.6129525929689408, accuracy = 0.8478\n",
      "Epoch 26, loss = 1.9835145864080876, test_loss = 1.6130440086126328, accuracy = 0.8473\n",
      "Epoch 27, loss = 1.9834214550383547, test_loss = 1.613280549645424, accuracy = 0.8471\n",
      "Epoch 28, loss = 1.982891363793231, test_loss = 1.6142138153314591, accuracy = 0.8465\n",
      "Epoch 29, loss = 1.9820084338492536, test_loss = 1.613252404332161, accuracy = 0.8476\n",
      "Epoch 30, loss = 1.981466823943118, test_loss = 1.6121480464935303, accuracy = 0.8484\n",
      "Epoch 31, loss = 1.9816698348268549, test_loss = 1.612678772211075, accuracy = 0.8479\n",
      "Epoch 32, loss = 1.9802330757709259, test_loss = 1.6123590141534805, accuracy = 0.8484\n",
      "Epoch 33, loss = 1.9805840852412773, test_loss = 1.6125238418579102, accuracy = 0.8495\n",
      "Epoch 34, loss = 1.980193166022605, test_loss = 1.6120552182197572, accuracy = 0.8482\n",
      "Epoch 35, loss = 1.979924006157733, test_loss = 1.6122261434793472, accuracy = 0.849\n",
      "Epoch 36, loss = 1.9795873469494758, test_loss = 1.611316305398941, accuracy = 0.8497\n",
      "Epoch 37, loss = 1.979739578734053, test_loss = 1.6113074481487275, accuracy = 0.8499\n",
      "Epoch 38, loss = 1.978719397808643, test_loss = 1.6113859921693803, accuracy = 0.8489\n",
      "Epoch 39, loss = 1.9786078158845293, test_loss = 1.6113272160291672, accuracy = 0.85\n",
      "Epoch 40, loss = 1.97847379420666, test_loss = 1.6115966111421585, accuracy = 0.8493\n",
      "Epoch 41, loss = 1.9777051337221836, test_loss = 1.6109929621219634, accuracy = 0.8508\n",
      "Epoch 42, loss = 1.9775254127827095, test_loss = 1.6108534395694734, accuracy = 0.8493\n",
      "Epoch 43, loss = 1.9773702946115048, test_loss = 1.6106864005327224, accuracy = 0.8497\n",
      "Epoch 44, loss = 1.976904733637546, test_loss = 1.6105101823806762, accuracy = 0.851\n",
      "Epoch 45, loss = 1.976701892183182, test_loss = 1.6098007261753082, accuracy = 0.8516\n",
      "Epoch 46, loss = 1.9760591999013373, test_loss = 1.6099050492048264, accuracy = 0.8516\n",
      "Epoch 47, loss = 1.9760210346668325, test_loss = 1.6102981954813003, accuracy = 0.8506\n",
      "Epoch 48, loss = 1.9763528879652632, test_loss = 1.6098265498876572, accuracy = 0.8515\n",
      "Epoch 49, loss = 1.9755334960653428, test_loss = 1.6100126206874847, accuracy = 0.8515\n",
      "Epoch 50, loss = 1.9755141856822562, test_loss = 1.6094822108745575, accuracy = 0.8514\n",
      "Epoch 51, loss = 1.9752775273424514, test_loss = 1.6100175350904464, accuracy = 0.8506\n",
      "Epoch 52, loss = 1.9752693145833118, test_loss = 1.6088252753019332, accuracy = 0.8525\n",
      "Epoch 53, loss = 1.974646761569571, test_loss = 1.609305527806282, accuracy = 0.8531\n",
      "Epoch 54, loss = 1.9742631770194845, test_loss = 1.6108921587467193, accuracy = 0.851\n",
      "Epoch 55, loss = 1.974362270882789, test_loss = 1.6091948926448822, accuracy = 0.8512\n",
      "Epoch 56, loss = 1.9738179095247959, test_loss = 1.6095531016588212, accuracy = 0.852\n",
      "Epoch 57, loss = 1.9736477369957781, test_loss = 1.6091514706611634, accuracy = 0.8518\n",
      "Epoch 58, loss = 1.973545364623374, test_loss = 1.6083017587661743, accuracy = 0.8529\n",
      "Epoch 59, loss = 1.9734337040718566, test_loss = 1.6082868874073029, accuracy = 0.8533\n",
      "Epoch 60, loss = 1.9731992696193938, test_loss = 1.6086115717887879, accuracy = 0.8532\n",
      "Epoch 61, loss = 1.972529244930186, test_loss = 1.6079634785652162, accuracy = 0.8521\n",
      "Epoch 62, loss = 1.972709399081291, test_loss = 1.6080088406801223, accuracy = 0.8522\n",
      "Epoch 63, loss = 1.9723936365005819, test_loss = 1.6084831595420837, accuracy = 0.8524\n",
      "Epoch 64, loss = 1.9718466581182277, test_loss = 1.60876105427742, accuracy = 0.8526\n",
      "Epoch 65, loss = 1.971225888678368, test_loss = 1.6080705612897872, accuracy = 0.8525\n",
      "Epoch 66, loss = 1.9713542674450164, test_loss = 1.6068261563777924, accuracy = 0.8549\n",
      "Epoch 67, loss = 1.9713908971624172, test_loss = 1.6077646881341934, accuracy = 0.8548\n",
      "Epoch 68, loss = 1.9709189998342636, test_loss = 1.607356983423233, accuracy = 0.8536\n",
      "Epoch 69, loss = 1.9707241479386675, test_loss = 1.6071729779243469, accuracy = 0.8532\n",
      "Epoch 70, loss = 1.9706375035833805, test_loss = 1.606482344865799, accuracy = 0.8543\n",
      "Epoch 71, loss = 1.9703426949521328, test_loss = 1.607261100411415, accuracy = 0.8536\n",
      "Epoch 72, loss = 1.9704020774110835, test_loss = 1.6072566330432891, accuracy = 0.8537\n",
      "Epoch 73, loss = 1.9701506107411486, test_loss = 1.6068738579750061, accuracy = 0.8548\n",
      "Epoch 74, loss = 1.969878915522961, test_loss = 1.6068252265453338, accuracy = 0.8539\n",
      "Epoch 75, loss = 1.9693945412940168, test_loss = 1.6065643936395646, accuracy = 0.854\n",
      "Epoch 76, loss = 1.9690741199128172, test_loss = 1.6065591067075728, accuracy = 0.8545\n",
      "Epoch 77, loss = 1.9691236120589235, test_loss = 1.6067473322153092, accuracy = 0.8547\n",
      "Epoch 78, loss = 1.969178613196028, test_loss = 1.606223687529564, accuracy = 0.8545\n",
      "Epoch 79, loss = 1.9690650990668763, test_loss = 1.605859214067459, accuracy = 0.8543\n",
      "Epoch 80, loss = 1.9683849456462454, test_loss = 1.606300839781761, accuracy = 0.8545\n",
      "Epoch 81, loss = 1.9681135294285226, test_loss = 1.6063044309616088, accuracy = 0.8551\n",
      "Epoch 82, loss = 1.968501216807264, test_loss = 1.6059129267930985, accuracy = 0.8541\n",
      "Epoch 83, loss = 1.9685288748842604, test_loss = 1.6050806403160096, accuracy = 0.8554\n",
      "Epoch 84, loss = 1.9685341738639994, test_loss = 1.6056778967380523, accuracy = 0.8559\n",
      "Epoch 85, loss = 1.9681879723325688, test_loss = 1.6058706104755402, accuracy = 0.8553\n",
      "Epoch 86, loss = 1.9676558220640141, test_loss = 1.6047809720039368, accuracy = 0.8562\n",
      "Epoch 87, loss = 1.9673523502146943, test_loss = 1.606164962053299, accuracy = 0.854\n",
      "Epoch 88, loss = 1.967448891477382, test_loss = 1.604887980222702, accuracy = 0.8553\n",
      "Epoch 89, loss = 1.967270761855105, test_loss = 1.6047956496477127, accuracy = 0.8552\n",
      "Epoch 90, loss = 1.9669758923510288, test_loss = 1.6052385479211808, accuracy = 0.8556\n",
      "Epoch 91, loss = 1.9666062126768395, test_loss = 1.604973030090332, accuracy = 0.8558\n",
      "Epoch 92, loss = 1.9667192814197947, test_loss = 1.6053063839673996, accuracy = 0.8552\n",
      "Epoch 93, loss = 1.9662866952571463, test_loss = 1.6053323775529862, accuracy = 0.8543\n",
      "Epoch 94, loss = 1.9665093817609423, test_loss = 1.605057418346405, accuracy = 0.8559\n",
      "Epoch 95, loss = 1.9654426447888638, test_loss = 1.6044584184885025, accuracy = 0.8566\n",
      "Epoch 96, loss = 1.9659332772518725, test_loss = 1.6047571390867232, accuracy = 0.8562\n",
      "Epoch 97, loss = 1.9655298141722983, test_loss = 1.6052411437034606, accuracy = 0.8548\n",
      "Epoch 98, loss = 1.9657335788645642, test_loss = 1.6043301314115523, accuracy = 0.8559\n",
      "Epoch 99, loss = 1.9653909333208774, test_loss = 1.6043618887662887, accuracy = 0.8557\n",
      "Epoch 100, loss = 1.9657346517481702, test_loss = 1.6035931527614593, accuracy = 0.8571\n",
      "Epoch 101, loss = 1.9652163566427028, test_loss = 1.6041823118925094, accuracy = 0.8562\n",
      "Epoch 102, loss = 1.965107057956939, test_loss = 1.6041021466255188, accuracy = 0.8564\n",
      "Epoch 103, loss = 1.9647620348220176, test_loss = 1.6046214669942855, accuracy = 0.8576\n",
      "Epoch 104, loss = 1.964303111015482, test_loss = 1.6038066774606705, accuracy = 0.8563\n",
      "Epoch 105, loss = 1.9646404195339122, test_loss = 1.6033165246248244, accuracy = 0.8573\n",
      "Epoch 106, loss = 1.964300782629784, test_loss = 1.6038600593805312, accuracy = 0.8567\n",
      "Epoch 107, loss = 1.9645189858497458, test_loss = 1.603550338745117, accuracy = 0.8568\n",
      "Epoch 108, loss = 1.964225438807873, test_loss = 1.603170895576477, accuracy = 0.8571\n",
      "Epoch 109, loss = 1.963863429110101, test_loss = 1.6032112032175063, accuracy = 0.8576\n",
      "Epoch 110, loss = 1.9635408254379922, test_loss = 1.6033844351768494, accuracy = 0.8571\n",
      "Epoch 111, loss = 1.9634236112554022, test_loss = 1.6036177664995193, accuracy = 0.8568\n",
      "Epoch 112, loss = 1.963233756004496, test_loss = 1.6030506312847137, accuracy = 0.8579\n",
      "Epoch 113, loss = 1.9633581399917603, test_loss = 1.603478693962097, accuracy = 0.8572\n",
      "Epoch 114, loss = 1.9633022896786954, test_loss = 1.6031684428453445, accuracy = 0.8576\n",
      "Epoch 115, loss = 1.9632495413435267, test_loss = 1.6026378482580186, accuracy = 0.8583\n",
      "Epoch 116, loss = 1.9631887420694878, test_loss = 1.6035076886415482, accuracy = 0.8584\n",
      "Epoch 117, loss = 1.9630872442367229, test_loss = 1.6029415816068648, accuracy = 0.8565\n",
      "Epoch 118, loss = 1.9625753965783626, test_loss = 1.6030553877353668, accuracy = 0.8581\n",
      "Epoch 119, loss = 1.962552886820854, test_loss = 1.603742927312851, accuracy = 0.8563\n",
      "Epoch 120, loss = 1.9630950283496937, test_loss = 1.6027682989835739, accuracy = 0.858\n",
      "Epoch 121, loss = 1.9625901795448142, test_loss = 1.6030587315559388, accuracy = 0.8563\n",
      "Epoch 122, loss = 1.9623313934245008, test_loss = 1.60252183675766, accuracy = 0.858\n",
      "Epoch 123, loss = 1.962167833713775, test_loss = 1.6025357127189637, accuracy = 0.8576\n",
      "Epoch 124, loss = 1.9615869588040291, test_loss = 1.6019515842199326, accuracy = 0.8581\n",
      "Epoch 125, loss = 1.961588625197715, test_loss = 1.6021975785493852, accuracy = 0.8588\n",
      "Epoch 126, loss = 1.9614939085980678, test_loss = 1.602309024333954, accuracy = 0.8585\n",
      "Epoch 127, loss = 1.9617043835051515, test_loss = 1.601927027106285, accuracy = 0.8581\n",
      "Epoch 128, loss = 1.9615101347578332, test_loss = 1.6019715756177901, accuracy = 0.8594\n",
      "Epoch 129, loss = 1.9610043089440528, test_loss = 1.601612287759781, accuracy = 0.8584\n",
      "Epoch 130, loss = 1.9611389616702466, test_loss = 1.601742720603943, accuracy = 0.8589\n",
      "Epoch 131, loss = 1.9610711229608413, test_loss = 1.601546287536621, accuracy = 0.859\n",
      "Epoch 132, loss = 1.9604659704451866, test_loss = 1.6023984044790267, accuracy = 0.8597\n",
      "Epoch 133, loss = 1.9609198047759686, test_loss = 1.6015774935483933, accuracy = 0.8585\n",
      "Epoch 134, loss = 1.9601301457019562, test_loss = 1.6013360410928725, accuracy = 0.8591\n",
      "Epoch 135, loss = 1.9603543185173198, test_loss = 1.6020440071821214, accuracy = 0.8583\n",
      "Epoch 136, loss = 1.9601196791263338, test_loss = 1.6014298230409623, accuracy = 0.8594\n",
      "Epoch 137, loss = 1.9604111991030104, test_loss = 1.6013707488775253, accuracy = 0.86\n",
      "Epoch 138, loss = 1.9600690699638204, test_loss = 1.6012842446565627, accuracy = 0.8598\n",
      "Epoch 139, loss = 1.9594802932536348, test_loss = 1.6012563198804854, accuracy = 0.8582\n",
      "Epoch 140, loss = 1.959631217286942, test_loss = 1.6016199737787247, accuracy = 0.8588\n",
      "Epoch 141, loss = 1.959567505755323, test_loss = 1.6017201602458955, accuracy = 0.8591\n",
      "Epoch 142, loss = 1.9596482616789797, test_loss = 1.6015349119901656, accuracy = 0.8588\n",
      "Epoch 143, loss = 1.9592591833561024, test_loss = 1.6010067224502564, accuracy = 0.86\n",
      "Epoch 144, loss = 1.9591937009324418, test_loss = 1.600988045334816, accuracy = 0.8599\n",
      "Epoch 145, loss = 1.9590856039777715, test_loss = 1.6008154720067977, accuracy = 0.8596\n",
      "Epoch 146, loss = 1.9590978896364253, test_loss = 1.6009504973888398, accuracy = 0.8594\n",
      "Epoch 147, loss = 1.9591577255979498, test_loss = 1.6013507425785065, accuracy = 0.8593\n",
      "Epoch 148, loss = 1.958805005601112, test_loss = 1.601846280694008, accuracy = 0.8592\n",
      "Epoch 149, loss = 1.9586981996576838, test_loss = 1.6004584461450577, accuracy = 0.861\n",
      "Epoch 150, loss = 1.9584843356558617, test_loss = 1.6009589344263078, accuracy = 0.8595\n"
     ]
    }
   ],
   "source": [
    "train.train_distill(teacher, student_distill, optimizer_student_distill, criterion_student_distill, train_iter, test_iter, device, num_epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
