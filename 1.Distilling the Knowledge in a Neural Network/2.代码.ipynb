{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TemperatureSoftmax\n",
    "class TemperatureSoftmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemperatureSoftmax, self).__init__()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # 对 dim=1 进行带有温度系数的 softmax\n",
    "        return torch.softmax(input_tensor / 1, dim=1)\n",
    "\n",
    "# Define teacher model\n",
    "teacher = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 625),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(625, 10),\n",
    "    TemperatureSoftmax(),\n",
    ")\n",
    "\n",
    "# X = torch.randn(1, 1, 28, 28)\n",
    "# for layer in teacher:\n",
    "    # X = layer(X)\n",
    "    # print(layer.__class__.__name__, \"output shape:\\t\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student model\n",
    "student = nn.Sequential(\n",
    "    nn.Flatten(), nn.Linear(28 * 28, 1000), nn.Sigmoid(),nn.Dropout(0.5), nn.Linear(1000, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "student.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset and create data loaders\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"../data\", train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root=\"../data\", train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models and data to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher = teacher.to(device)\n",
    "student = student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "criterion_student = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.RMSprop(teacher.parameters(), lr=1e-4)\n",
    "optimizer_student = optim.SGD(student.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define teacher evaluation function\n",
    "def evaluate_teacher(net, criterion, testloader, device):\n",
    "    net.eval()\t# Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = y_hat.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    print(f\"Test loss = {running_loss / len(testloader)}, accuracy = {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define teacher training function\n",
    "def train_teacher(net, optimizer, criterion, trainloader, testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\t# Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_teacher(net, criterion, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_teacher(teacher, optimizer_teacher, criterion_teacher, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student evaluation function\n",
    "def evaluate_student(net, criterion, testloader, device):\n",
    "    net.eval()\t# Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = y_hat.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    print(f\"Test loss = {running_loss / len(testloader)}, accuracy = {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student training function\n",
    "def train_student(net, optimizer, criterion, trainloader,testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\t# Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_student(net, criterion, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_student(student, optimizer_student, criterion_student, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distill(teacher, student, optimizer_student, criterion_student, trainloader, testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        teacher.eval()\n",
    "        student.train()\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_teacher = teacher(X)\n",
    "            y_hat = student(X)\n",
    "            loss = 5 * criterion_student(y_hat, y) + F.kl_div(y_hat.log(), y_teacher, reduction=\"batchmean\")\n",
    "            \n",
    "            optimizer_student.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_student.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_student(student, criterion_student, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distill(teacher, student, optimizer_student, criterion_student, trainloader, testloader, device, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
