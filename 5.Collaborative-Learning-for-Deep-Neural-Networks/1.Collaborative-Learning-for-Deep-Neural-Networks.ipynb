{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collaborative Learning for Deep Neural Networks**\n",
    "\n",
    "#### **Abstract**\n",
    "\n",
    "- 引入了协作学习方法，其中**同一网络的多个分类器头同时**在相同的训练数据上进行训练。\n",
    "- 协作学习方法融合了多种学习方法的优点，包括辅助训练、多任务学习和知识蒸馏。**不增加额外的推断成本。**\n",
    "- 协作学习的**两个关键机制：**\n",
    "   - 第一，多个分类器头对相同示例的多个视图一致性提供了额外信息，**同时对每个分类器进行了正则化**，以提高泛化能力。\n",
    "   - 第二，通过中间级表示（ILR）共享和反向传播重新缩放，**汇总了来自所有头部的梯度流**，降低了训练的计算复杂性，**同时有助于监督共享层。**\n",
    "\n",
    "- 数据集：*CIFAR, ImageNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "#### **Introduction**\n",
    "- *The per-layer network weight distribution **shows that** ILR sharing reduces the number of \"dead\" filter weights in the bottom layers **due to** the vanishing gradient issue, thereby enlarging the network capacity.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
