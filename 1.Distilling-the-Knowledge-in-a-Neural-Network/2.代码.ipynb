{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TemperatureSoftmax\n",
    "class TemperatureSoftmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemperatureSoftmax, self).__init__()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # 对 dim=1 进行带有温度系数的 softmax\n",
    "        return torch.softmax(input_tensor / 1, dim=1)\n",
    "\n",
    "# Define teacher model\n",
    "teacher = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 625),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(625, 10),\n",
    "    TemperatureSoftmax(),\n",
    ")\n",
    "\n",
    "# X = torch.randn(1, 1, 28, 28)\n",
    "# for layer in teacher:\n",
    "    # X = layer(X)\n",
    "    # print(layer.__class__.__name__, \"output shape:\\t\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student model\n",
    "student = nn.Sequential(\n",
    "    nn.Flatten(), nn.Linear(28 * 28, 1000), nn.Sigmoid(),nn.Dropout(0.5), nn.Linear(1000, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=1000, bias=True)\n",
       "  (2): Sigmoid()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "student.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset and create data loaders\n",
    "import data_loader\n",
    "\n",
    "train_iter, test_iter = data_loader.load_data_fashion_mnist(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "d2l.load_data_fashion_mnist(batch_size=128, resize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models and data to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher = teacher.to(device)\n",
    "student = student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "criterion_student = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.RMSprop(teacher.parameters(), lr=1e-4)\n",
    "optimizer_student = optim.SGD(student.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define teacher evaluation function\n",
    "def evaluate_teacher(net, criterion, testloader, device):\n",
    "    net.eval()\t# Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = y_hat.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    print(f\"Test loss = {running_loss / len(testloader)}, accuracy = {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define teacher training function\n",
    "def train_teacher(net, optimizer, criterion, trainloader, testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\t# Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_teacher(net, criterion, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 1.8600780948647049\n",
      "Epoch 2, loss = 1.6323614804221114\n",
      "Epoch 3, loss = 1.575677398171252\n",
      "Epoch 4, loss = 1.5538970979292002\n",
      "Epoch 5, loss = 1.540759448303597\n",
      "Test loss = 1.508636889578421, accuracy = 0.9548\n",
      "Epoch 6, loss = 1.5320327200615076\n",
      "Epoch 7, loss = 1.5264999281877139\n",
      "Epoch 8, loss = 1.5212465628886274\n",
      "Epoch 9, loss = 1.5161578268892983\n",
      "Epoch 10, loss = 1.5114354317122176\n",
      "Test loss = 1.491573232638685, accuracy = 0.9701\n"
     ]
    }
   ],
   "source": [
    "train_teacher(teacher, optimizer_teacher, criterion_teacher, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student evaluation function\n",
    "def evaluate_student(net, criterion, testloader, device):\n",
    "    net.eval()\t# Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = y_hat.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    print(f\"Test loss = {running_loss / len(testloader)}, accuracy = {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define student training function\n",
    "def train_student(net, optimizer, criterion, trainloader,testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\t# Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_student(net, criterion, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 1.629913806406928\n",
      "Epoch 2, loss = 0.914098279054231\n",
      "Epoch 3, loss = 0.7158152863287977\n",
      "Epoch 4, loss = 0.6220535689960919\n",
      "Epoch 5, loss = 0.5684157444088698\n",
      "Test loss = 0.4377809646952001, accuracy = 0.8846\n",
      "Epoch 6, loss = 0.5328225425438586\n",
      "Epoch 7, loss = 0.5026534875191605\n",
      "Epoch 8, loss = 0.48351090104341\n",
      "Epoch 9, loss = 0.464187063642148\n",
      "Epoch 10, loss = 0.45269791257661035\n",
      "Test loss = 0.36054175620592094, accuracy = 0.8988\n"
     ]
    }
   ],
   "source": [
    "train_student(student, optimizer_student, criterion_student, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distill(teacher, student, optimizer_student, criterion_student, trainloader, testloader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        teacher.eval()\n",
    "        student.train()\n",
    "        running_loss = 0.0\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_teacher = teacher(X)\n",
    "            y_hat = student(X)\n",
    "            loss = 5 * criterion_student(y_hat, y) + F.kl_div(y_hat.log(), y_teacher, reduction=\"batchmean\")\n",
    "            \n",
    "            optimizer_student.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_student.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, loss = {running_loss / len(trainloader)}\")\n",
    "        if epoch % 5 == 5 - 1:\n",
    "            evaluate_student(student, criterion_student, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = nan\n",
      "Epoch 2, loss = nan\n",
      "Epoch 3, loss = nan\n",
      "Epoch 4, loss = -1.4691381464634876\n",
      "Epoch 5, loss = -1.658426731380064\n",
      "Test loss = 0.2927684231390116, accuracy = 0.9144\n",
      "Epoch 6, loss = -1.822038261112628\n",
      "Epoch 7, loss = -1.9480363682134827\n",
      "Epoch 8, loss = -2.0780909328318353\n",
      "Epoch 9, loss = -2.1798136198698583\n",
      "Epoch 10, loss = -2.3125697112540955\n",
      "Test loss = 0.2574114916209556, accuracy = 0.925\n",
      "Epoch 11, loss = -2.3981384280393883\n",
      "Epoch 12, loss = -2.477684957386334\n",
      "Epoch 13, loss = -2.592115228364208\n",
      "Epoch 14, loss = -2.667604061077907\n",
      "Epoch 15, loss = -2.7550074886411493\n",
      "Test loss = 0.23327444908739645, accuracy = 0.9301\n",
      "Epoch 16, loss = -2.8285503107855825\n",
      "Epoch 17, loss = -2.8967212115777836\n",
      "Epoch 18, loss = -2.971695560382119\n",
      "Epoch 19, loss = -3.039699140133888\n",
      "Epoch 20, loss = -3.09438220880179\n",
      "Test loss = 0.20313910609464855, accuracy = 0.9407\n",
      "Epoch 21, loss = -3.162474264722389\n",
      "Epoch 22, loss = -3.232210760685935\n",
      "Epoch 23, loss = -3.28618391185427\n",
      "Epoch 24, loss = -3.3515251343692545\n",
      "Epoch 25, loss = -3.3894631023854336\n",
      "Test loss = 0.1798878844792047, accuracy = 0.9469\n",
      "Epoch 26, loss = -3.4408294539461766\n",
      "Epoch 27, loss = -3.485108322680378\n",
      "Epoch 28, loss = -3.5321684625865553\n",
      "Epoch 29, loss = -3.582810274827709\n",
      "Epoch 30, loss = -3.6234897677578144\n",
      "Test loss = 0.16304954251899278, accuracy = 0.9515\n",
      "Epoch 31, loss = -3.6608204206169797\n",
      "Epoch 32, loss = -3.7026210354843627\n",
      "Epoch 33, loss = -3.7301851122109873\n",
      "Epoch 34, loss = -3.763734534859403\n",
      "Epoch 35, loss = -3.801733852703688\n",
      "Test loss = 0.1489795143568676, accuracy = 0.9556\n",
      "Epoch 36, loss = -3.8441830474430563\n",
      "Epoch 37, loss = -3.8681462924363514\n",
      "Epoch 38, loss = -3.911689843704451\n",
      "Epoch 39, loss = -3.942139184805376\n",
      "Epoch 40, loss = -3.9679919468568587\n",
      "Test loss = 0.13812699660222647, accuracy = 0.96\n",
      "Epoch 41, loss = -3.987007396307581\n",
      "Epoch 42, loss = -4.026468190048804\n",
      "Epoch 43, loss = -4.049818523911271\n",
      "Epoch 44, loss = -4.072234533488878\n",
      "Epoch 45, loss = -4.099339301652237\n",
      "Test loss = 0.13047783269953642, accuracy = 0.9612\n",
      "Epoch 46, loss = -4.130972831233986\n",
      "Epoch 47, loss = -4.152474097859885\n",
      "Epoch 48, loss = -4.179620465744279\n",
      "Epoch 49, loss = -4.197187419639214\n",
      "Epoch 50, loss = -4.215482897341633\n",
      "Test loss = 0.12116670912526595, accuracy = 0.9629\n"
     ]
    }
   ],
   "source": [
    "train_distill(teacher, student, optimizer_student, criterion_student, trainloader, testloader, device, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
